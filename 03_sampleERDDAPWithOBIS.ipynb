{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365b6a32",
      "metadata": {
        "id": "365b6a32"
      },
      "outputs": [],
      "source": [
        "# # use erddapy to get some data\n",
        "# from erddapy import ERDDAP\n",
        "# import numpy as np\n",
        "#\n",
        "# e = ERDDAP(\n",
        "#     server=\"https://erddap.marine.usf.edu/erddap\",\n",
        "#     protocol=\"griddap\",\n",
        "# )\n",
        "#\n",
        "# e.dataset_id = \"jplMURSST41anom1day\"\n",
        "# print(f\"variables in this dataset:\\n\\n{e.variables}\")\n",
        "#\n",
        "# # set bounds to reduce download size\n",
        "# e.constraints = {\n",
        "#     'time>=': '2003-06-07T09:00:00Z',\n",
        "#     'time<=': '2024-06-07T09:00:00Z',\n",
        "#     'time_step': 1,\n",
        "#     'latitude>=': np.float64(lat - 1),\n",
        "#     'latitude<=': np.float64(lat + 1),\n",
        "#     'latitude_step': 1,\n",
        "#     'longitude>=': np.float64(lon - 1),\n",
        "#     'longitude<=': np.float64(lon + 1),\n",
        "#     'longitude_step': 1\n",
        "# }\n",
        "#\n",
        "# Download as a NetCDF to disk\n",
        "# nc_filename = e.download_file(\".nc\")\n",
        "# (under the hood this uses the GRiDDAP `.nc` URL)\n",
        "#\n",
        "# ds = e.to_xarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaOPos1cLi5o",
        "outputId": "76e9411e-7d9a-4344-9071-fccf1e7602ea"
      },
      "id": "zaOPos1cLi5o",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e323ac",
      "metadata": {
        "id": "62e323ac",
        "outputId": "d0481caf-a6aa-4c5f-d923-07c29c7bc13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask in /home/tylar/miniconda3/lib/python3.12/site-packages (2025.5.1)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (2025.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (1.0.0)\n",
            "Requirement already satisfied: locket in /home/tylar/miniconda3/lib/python3.12/site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
            "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "Successfully installed pyarrow-20.0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install dask pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7b03ded8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "7b03ded8",
        "outputId": "01b61134-2407-45a8-cfff-abde15c5a9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Series' object has no attribute 'persist'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1779081864>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# build a Dask DataFrame of salinities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m sal = ds[\"so\"].sel(\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decimalLatitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlongitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decimalLongitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'persist'"
          ]
        }
      ],
      "source": [
        "# sample all taxa occurrence points for ERDDAP data values:\n",
        "# data has already been downloaded as .nc\n",
        "# example:\n",
        "# https://erddap.marine.usf.edu/erddap/griddap/cmems_salinity.graph?so%5B(2023-06-16)%5D%5B(0.494025)%5D%5B(-80.0):(90.0)%5D%5B(-180.0):(179.9167)%5D&.draw=surface&.vars=longitude%7Clatitude%7Cso&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\n",
        "\n",
        "import pickle\n",
        "\n",
        "import dask.dataframe as dd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/occurrences.pkl', 'rb') as f:\n",
        "    occurrences = pickle.load(f)  # pandas.df\n",
        "\n",
        "import xarray as xr\n",
        "ds = xr.open_dataset(\n",
        "    \"/content/drive/MyDrive/cmems_salinity_44d2_bc4b_70b2_U1749495233099.nc\",\n",
        "    chunks={\"time\": 1, \"latitude\": 500, \"longitude\": 500}\n",
        ")\n",
        "\n",
        "\n",
        "# build a Dask DataFrame of salinities\n",
        "sal = ds[\"so\"].sel(\n",
        "    latitude=occurrences[\"decimalLatitude\"].persist(),\n",
        "    longitude=occurrences[\"decimalLongitude\"].persist(),\n",
        "    method=\"nearest\"\n",
        ")\n",
        "# this is a dask Array; turn it into a dask Series\n",
        "occurrences[\"salinity\"] = sal.to_dask_dataframe(name=\"salinity\")[\"salinity\"]\n",
        "\n",
        "# trigger computation in manageable chunks:\n",
        "result = occurrences.compute()\n",
        "print(result.head())\n",
        "\n",
        "# for occurrence in occurrences.iterrows():\n",
        "#     # adjust names if dims are named 'latitude'/'longitude' or 'lat'/'lon'\n",
        "#     print(occurrence[\"decimalLatitude\"])\n",
        "#     val = ds[\"so\"].sel(\n",
        "#         latitude=occurrence[\"decimalLatitude\"],\n",
        "#         longitude=occurrence[\"decimalLongitude\"],\n",
        "#         method=\"nearest\"\n",
        "#     ).values\n",
        "\n",
        "#     print(f\"At ({occurrence[\"decimalLatitude\"]}, {occurrence[\"decimalLongitude\"]}), so = {val}\")\n",
        "\n",
        "# lat = 60\n",
        "# lon = -60\n",
        "\n",
        "# # Open file with xarray\n",
        "# ds = xr.open_dataset(\"data/cmems_salinity_44d2_bc4b_70b2_U1749495233099.nc\")\n",
        "\n",
        "\n",
        "# # adjust names if dims are named 'latitude'/'longitude' or 'lat'/'lon'\n",
        "# val = ds[\"so\"].sel(\n",
        "#     latitude=lat,\n",
        "#     longitude=lon,\n",
        "#     method=\"nearest\"\n",
        "# ).values\n",
        "\n",
        "# print(f\"At ({lat}, {lon}), so = {val}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}