{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365b6a32",
      "metadata": {
        "id": "365b6a32"
      },
      "outputs": [],
      "source": [
        "# # use erddapy to get some data\n",
        "# from erddapy import ERDDAP\n",
        "# import numpy as np\n",
        "#\n",
        "# e = ERDDAP(\n",
        "#     server=\"https://erddap.marine.usf.edu/erddap\",\n",
        "#     protocol=\"griddap\",\n",
        "# )\n",
        "#\n",
        "# e.dataset_id = \"jplMURSST41anom1day\"\n",
        "# print(f\"variables in this dataset:\\n\\n{e.variables}\")\n",
        "#\n",
        "# # set bounds to reduce download size\n",
        "# e.constraints = {\n",
        "#     'time>=': '2003-06-07T09:00:00Z',\n",
        "#     'time<=': '2024-06-07T09:00:00Z',\n",
        "#     'time_step': 1,\n",
        "#     'latitude>=': np.float64(lat - 1),\n",
        "#     'latitude<=': np.float64(lat + 1),\n",
        "#     'latitude_step': 1,\n",
        "#     'longitude>=': np.float64(lon - 1),\n",
        "#     'longitude<=': np.float64(lon + 1),\n",
        "#     'longitude_step': 1\n",
        "# }\n",
        "#\n",
        "# Download as a NetCDF to disk\n",
        "# nc_filename = e.download_file(\".nc\")\n",
        "# (under the hood this uses the GRiDDAP `.nc` URL)\n",
        "#\n",
        "# ds = e.to_xarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zaOPos1cLi5o",
        "outputId": "76e9411e-7d9a-4344-9071-fccf1e7602ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zaOPos1cLi5o",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e323ac",
      "metadata": {
        "id": "62e323ac",
        "outputId": "d0481caf-a6aa-4c5f-d923-07c29c7bc13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask in /home/tylar/miniconda3/lib/python3.12/site-packages (2025.5.1)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (2025.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from dask) (1.0.0)\n",
            "Requirement already satisfied: locket in /home/tylar/miniconda3/lib/python3.12/site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
            "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "Successfully installed pyarrow-20.0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install dask pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7b03ded8",
      "metadata": {
        "id": "7b03ded8",
        "outputId": "b479a2d2-e054-4fec-ae31-cbcc4a515020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot use a dict-like object for selection on a dimension that does not have a MultiIndex",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2636486507>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# build a Dask DataFrame of salinities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m sal = ds[\"so\"].sel(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decimalLatitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlongitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decimalLongitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36msel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0mDimensions\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \"\"\"\n\u001b[0;32m-> 1690\u001b[0;31m         ds = self._to_temp_dataset().sel(\n\u001b[0m\u001b[1;32m   1691\u001b[0m             \u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36msel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \"\"\"\n\u001b[1;32m   2889\u001b[0m         \u001b[0mindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meither_dict_or_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m         query_results = map_index_queries(\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mmap_index_queries\u001b[0;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexSelResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_sel_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/indexes.py\u001b[0m in \u001b[0;36msel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_query_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0;34m\"cannot use a dict-like object for selection on \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;34m\"a dimension that does not have a MultiIndex\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot use a dict-like object for selection on a dimension that does not have a MultiIndex"
          ]
        }
      ],
      "source": [
        "# sample all taxa occurrence points for ERDDAP data values:\n",
        "# data has already been downloaded as .nc\n",
        "# example:\n",
        "# https://erddap.marine.usf.edu/erddap/griddap/cmems_salinity.graph?so%5B(2023-06-16)%5D%5B(0.494025)%5D%5B(-80.0):(90.0)%5D%5B(-180.0):(179.9167)%5D&.draw=surface&.vars=longitude%7Clatitude%7Cso&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\n",
        "\n",
        "import pickle\n",
        "\n",
        "import dask.dataframe as dd\n",
        "with open('/content/drive/MyDrive/occurrences.pkl', 'rb') as f:\n",
        "    occurrences = pickle.load(f)  # pandas.df\n",
        "\n",
        "import xarray as xr\n",
        "ds = xr.open_dataset(\n",
        "    \"/content/drive/MyDrive/cmems_salinity_44d2_bc4b_70b2_U1749495233099.nc\",\n",
        "    chunks={\"time\": 1, \"latitude\": 500, \"longitude\": 500}\n",
        ")\n",
        "\n",
        "\n",
        "# build a Dask DataFrame of salinities\n",
        "sal = ds[\"so\"].sel(\n",
        "    latitude=occurrences[\"decimalLatitude\"],\n",
        "    longitude=occurrences[\"decimalLongitude\"],\n",
        "    method=\"nearest\"\n",
        ")\n",
        "# this is a dask Array; turn it into a dask Series\n",
        "occurrences[\"salinity\"] = sal.to_dask_dataframe(name=\"salinity\")[\"salinity\"]\n",
        "\n",
        "# trigger computation in manageable chunks:\n",
        "result = occurrences.compute()\n",
        "print(result.head())\n",
        "\n",
        "# for occurrence in occurrences.iterrows():\n",
        "#     # adjust names if dims are named 'latitude'/'longitude' or 'lat'/'lon'\n",
        "#     print(occurrence[\"decimalLatitude\"])\n",
        "#     val = ds[\"so\"].sel(\n",
        "#         latitude=occurrence[\"decimalLatitude\"],\n",
        "#         longitude=occurrence[\"decimalLongitude\"],\n",
        "#         method=\"nearest\"\n",
        "#     ).values\n",
        "\n",
        "#     print(f\"At ({occurrence[\"decimalLatitude\"]}, {occurrence[\"decimalLongitude\"]}), so = {val}\")\n",
        "\n",
        "# lat = 60\n",
        "# lon = -60\n",
        "\n",
        "# # Open file with xarray\n",
        "# ds = xr.open_dataset(\"data/cmems_salinity_44d2_bc4b_70b2_U1749495233099.nc\")\n",
        "\n",
        "\n",
        "# # adjust names if dims are named 'latitude'/'longitude' or 'lat'/'lon'\n",
        "# val = ds[\"so\"].sel(\n",
        "#     latitude=lat,\n",
        "#     longitude=lon,\n",
        "#     method=\"nearest\"\n",
        "# ).values\n",
        "\n",
        "# print(f\"At ({lat}, {lon}), so = {val}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}